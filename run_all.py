# run_all.py

import os
import sys
import subprocess
import re
import time
import webbrowser
import shutil
import json
import torch

def main():
    # â€”â€” 0. å¯è°ƒå‚æ•° â€”â€”  
    DATASET_ID   = "99"                         # åªå†™â€œ99â€
    DATASET_ID_3 = DATASET_ID.zfill(3)          # è‡ªåŠ¨è¡¥æˆâ€œ099â€
    PLAN_CONFIG  = "3d_fullres"                 # U-Net é…ç½®
    FOLD         = "0"                          # fold åºå·
    NUM_PROC     = "8"                          # å¹¶è¡Œè¿›ç¨‹æ•°
    EPOCHS       = "5"                          # è®­ç»ƒè½®æ•°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    NAME         = "Heart"                      # ä»»åŠ¡åç§°
    EXAMPLE_RAW  = "la_003_0000.nii.gz"         # Notebook ç¤ºä¾‹ç”¨æ–‡ä»¶å

    # â€”â€” 1. ç¯å¢ƒå˜é‡é›†ä¸­è®¾ç½® â€”â€”  
    os.environ.update({
        'NNUNET_DATASET_ID':   DATASET_ID,
        'NNUNET_PLAN_CONFIG':  PLAN_CONFIG,
        'NNUNET_FOLD':         FOLD,
        'NNUNET_NUM_PROC':     NUM_PROC,
        'NNUNET_EPOCH':        EPOCHS,
        'NaME':                NAME,
        'example_raw':         EXAMPLE_RAW,
        # â€”â€” è¯·æ”¹ä¸ºä½ æœ¬åœ°çš„ç»å¯¹è·¯å¾„ â€”â€”  
        'MSD_raw':             r"C:\Users\chen1myn\Documents\GitHub\nnUNet\DATASET\nnUNet_raw\Task02_Heart",
        'MSD_preprocessed_id': DATASET_ID,
        'nnUNet_raw':          r"C:\Users\chen1myn\Documents\GitHub\nnUNet\DATASET\nnUNet_raw",
        'nnUNet_preprocessed': r"C:\Users\chen1myn\Documents\GitHub\nnUNet\DATASET\nnUNet_preprocessed",
        'nnUNet_results':      r"C:\Users\chen1myn\Documents\GitHub\nnUNet\DATASET\nnUNet_results",
    })
    print("âœ… ç¯å¢ƒå˜é‡å·²è®¾ç½®")

    # â€”â€” 2. æ„é€ è·¯å¾„ â€”â€”  
    loc = f"Dataset{DATASET_ID_3}_{NAME}"
    preproc_folder = os.path.join(os.environ['nnUNet_preprocessed'], loc)
    model_folder   = os.path.join(
        os.environ['nnUNet_results'], loc,
        f"nnUNetTrainer__nnUNetPlans__{PLAN_CONFIG}"
    )
    ckpt = os.path.join(model_folder, f"fold_{FOLD}", "checkpoint_best.pth")

    # â€”â€” å¦‚æœé¢„å¤„ç† & è®­ç»ƒéƒ½å·²å®Œæˆï¼Œè·³è¿‡åˆ°å¯è§†åŒ– â€”â€”  
    if os.path.isdir(preproc_folder) and os.path.isfile(ckpt):
        print("âœ… å·²æ£€æµ‹åˆ°é¢„å¤„ç†ç›®å½•å’Œ checkpointï¼Œç›´æ¥å±•ç¤º")
        _write_config()
        _execute_notebook()
        _launch_server_and_open("show_executed.ipynb")
        return

    # â€”â€” 3. MSD è½¬æ¢ â€”â€”  
    if not os.path.isdir(preproc_folder):
        print("ğŸ”„ å¼€å§‹ MSD æ•°æ®è½¬æ¢ â€¦")
        from nnunetv2.dataset_conversion.convert_MSD_dataset import run_main_convert
        run_main_convert()
        print("âœ… MSD æ•°æ®è½¬æ¢å®Œæˆ")
    else:
        print("âœ… å·²å­˜åœ¨é¢„å¤„ç†ç›®å½•ï¼Œè·³è¿‡è½¬æ¢")

    # â€”â€” 4. è§„åˆ’ + é¢„å¤„ç† â€”â€”  
    print("ğŸ”„ å¼€å§‹ è§„åˆ’ä¸é¢„å¤„ç† â€¦")
    sys.argv = [
        "nnUNetv2_plan_and_preprocess",
        "-d", DATASET_ID,
        "--verify_dataset_integrity",
        "-np", NUM_PROC
    ]
    from nnunetv2.experiment_planning.plan_and_preprocess_entrypoints import plan_and_preprocess_entry
    plan_and_preprocess_entry()
    print("âœ… è§„åˆ’ä¸é¢„å¤„ç†å®Œæˆ")

    # â€”â€” 5. è®­ç»ƒ â€”â€”  
    if not os.path.isfile(ckpt):
        print("ğŸ”„ å¼€å§‹ è®­ç»ƒ â€¦")
        sys.argv = ["run_training.py", DATASET_ID, PLAN_CONFIG, FOLD]
        from nnunetv2.run.run_training import run_training_entry
        run_training_entry()
        print("âœ… è®­ç»ƒå®Œæˆï¼Œcheckpoint å·²ä¿å­˜")
    else:
        print("âœ… å·²å­˜åœ¨ checkpointï¼Œè·³è¿‡è®­ç»ƒ")

    # â€”â€” 6. æ¨ç† â€”â€”  
    print("ğŸ”„ å¼€å§‹ æ¨ç†ï¼Œç”Ÿæˆ imagesTs_predlowres â€¦")
    from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor

    predictor = nnUNetPredictor(
        tile_step_size=0.5,
        use_gaussian=True,
        use_mirroring=True,
        perform_everything_on_device=True,
        device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu"),
        verbose=False,
        verbose_preprocessing=False,
        allow_tqdm=True
    )
    predictor.initialize_from_trained_model_folder(
        model_folder,
        use_folds=(int(FOLD),),
        checkpoint_name="checkpoint_best.pth"
    )

    src = os.path.join(os.environ['nnUNet_raw'], loc, "imagesTr")
    ts  = os.path.join(os.environ['nnUNet_raw'], loc, "imagesTs")
    out = os.path.join(os.environ['nnUNet_raw'], loc, "imagesTs_predlowres")
    os.makedirs(ts,  exist_ok=True)
    os.makedirs(out, exist_ok=True)
    for f in os.listdir(src):
        if f.endswith("_0000.nii.gz"):
            dst = os.path.join(ts, f)
            if not os.path.exists(dst):
                shutil.copy(os.path.join(src, f), dst)

    predictor.predict_from_files(
        ts, out,
        save_probabilities=False,
        overwrite=True,
        num_processes_preprocessing=2,
        num_processes_segmentation_export=2,
        folder_with_segs_from_prev_stage=None,
        num_parts=1,
        part_id=0
    )
    print("âœ… æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š", out)

    # â€”â€” 7. å†™ config + æ‰§è¡Œ & å±•ç¤º Notebook â€”â€”  
    _write_config()
    _execute_notebook()
    _launch_server_and_open("show_executed.ipynb")


def _write_config():
    """
    å†™å…¥ config.jsonï¼Œä¾› show.ipynb è¯»å–ï¼š
    """
    cfg = {
        "nnUNet_raw": os.environ['nnUNet_raw'],
        "datasetid":  os.environ['NNUNET_DATASET_ID'],
        "NAME":       os.environ['NaME']
    }
    with open("config.json", "w") as f:
        json.dump(cfg, f, indent=2)
    print("âœ… å·²ç”Ÿæˆ config.json")


def _execute_notebook():
    """
    é¢„å…ˆæ‰§è¡Œ show.ipynb å¹¶è¾“å‡ºåˆ° show_executed.ipynb
    """
    print("ğŸš€ æ­£åœ¨ç”¨ nbconvert è¿è¡Œ show.ipynb â€¦")
    subprocess.run([
        "jupyter", "nbconvert",
        "--to", "notebook",
        "--execute", "show.ipynb",
        "--output", "show_executed.ipynb"
    ], check=True)
    print("âœ… Notebook å·²æ‰§è¡Œå®Œæ¯•ï¼Œè¾“å‡º show_executed.ipynb")


def _launch_server_and_open(nb_file: str):
    """
    å¯åŠ¨ notebook æœåŠ¡å¹¶æ‰“å¼€æ‰§è¡Œå¥½çš„ nb_file
    """
    cwd = os.getcwd()
    print("ğŸš€ å¯åŠ¨ Jupyter Serverï¼ˆ--no-browserï¼‰â€¦")
    proc = subprocess.Popen(
        ["jupyter", "notebook", "--no-browser", "--notebook-dir", cwd],
        cwd=cwd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True
    )

    base_url = None
    token    = None
    # ä»æ—¥å¿—é‡ŒæŠ“ token
    for line in proc.stdout:
        print(line, end="")
        m = re.search(r"(http://[^/\s]+:\d+)(?:/\S*)?\?token=(\w+)", line)
        if m:
            base_url = m.group(1)
            token    = m.group(2)
            break

    if not base_url or not token:
        raise RuntimeError("âŒ æ— æ³•è§£æ Jupyter token URL")

    url = f"{base_url}/notebooks/{nb_file}?token={token}"
    print(f"\nğŸš€ æ•è·åˆ°å¹¶æ‰“å¼€ï¼š\n    {url}\n")
    webbrowser.open(url)
    print("ï¼ˆå®Œæˆåè¯·åœ¨ç»ˆç«¯æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨ï¼‰")


if __name__ == "__main__":
    main()
